{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyBEyHy5yYFXcLUOcjyuBC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victornunesvidal/pucrj-mvp-machine-learning/blob/main/MVP_Modelo_Propensao_Afinidade_REV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo a seguir é um modelo de classificação que trás um ranking de priorização dos produtos (codigo_produto) mais propensos a serem comprados por cada codigo_cliente considerando todas as variáveis disponíveis.\n",
        "\n",
        "O dataset é um CSV com os seguintes campos separados por \";\":\n",
        "\n",
        "- codigo_cliente\n",
        "- codigo_produto\n",
        "- data_venda\n",
        "- unidades_vendidas\n",
        "- venda_bruta = valor da venda antes dos descontos\n",
        "- net_sales = valor da venda após os descontos\n",
        "- volume_kg = volume em kilogramas de cada venda\n",
        "- sistema_de_vendas = sistema pelo qual a venda foi feita (as vendas digitais são indicadas por \"02.BEES\")\n",
        "- tipologia = tipo do cliente (MERCEARIA, BAR, PADARIA, entre outros)\n",
        "- nivel_cliente = nivel do cliente baseado no ticket médio, classificado entre AAA (ticket médio de 15 mil/mês), AA (7 mil por mês), A, B, C, D, E e X.\n",
        "\n",
        "Os campos venda_bruta, net_sales e volume_kg foram retirados do modelo para evitar redundância com o campo unidades_vendidas, já que todos esses campos descrevem volume de vendas, só trocando a unidade de medida."
      ],
      "metadata": {
        "id": "JzBeqVo55lCQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSX8vyTvFUtD",
        "outputId": "9f008a3b-7fca-423b-9a5d-b7e1051f73c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeiras linhas do DataFrame:\n",
            "   codigo_cliente codigo_produto               data_venda sistema_de_vendas  \\\n",
            "0       100164574              _  2023-10-31 00:00:00,000            01.MC1   \n",
            "1       100164574              _  2023-11-30 00:00:00,000            01.MC1   \n",
            "2       100164574              _  2024-01-31 00:00:00,000            01.MC1   \n",
            "3       100164574              _  2024-02-29 00:00:00,000            01.MC1   \n",
            "4       100164574              _  2024-03-28 00:00:00,000            01.MC1   \n",
            "\n",
            "              tipologia nivel_cliente  unidades_vendidas  venda_bruta  \\\n",
            "0  AS 05 A 09 CHECK-OUT           AAA                  0          0.0   \n",
            "1  AS 05 A 09 CHECK-OUT           AAA                  0          0.0   \n",
            "2  AS 05 A 09 CHECK-OUT           AAA                  0          0.0   \n",
            "3  AS 05 A 09 CHECK-OUT           AAA                  0          0.0   \n",
            "4  AS 05 A 09 CHECK-OUT           AAA                  0          0.0   \n",
            "\n",
            "   net_sales  volume_kg  \n",
            "0        0.0        0.0  \n",
            "1        0.0        0.0  \n",
            "2        0.0        0.0  \n",
            "3        0.0        0.0  \n",
            "4        0.0        0.0  \n",
            "\n",
            "Informações do DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7854 entries, 0 to 7853\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   codigo_cliente     7854 non-null   int64  \n",
            " 1   codigo_produto     7854 non-null   object \n",
            " 2   data_venda         7854 non-null   object \n",
            " 3   sistema_de_vendas  7854 non-null   object \n",
            " 4   tipologia          7854 non-null   object \n",
            " 5   nivel_cliente      7854 non-null   object \n",
            " 6   unidades_vendidas  7854 non-null   int64  \n",
            " 7   venda_bruta        7854 non-null   float64\n",
            " 8   net_sales          7854 non-null   float64\n",
            " 9   volume_kg          7854 non-null   float64\n",
            "dtypes: float64(3), int64(2), object(5)\n",
            "memory usage: 613.7+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# 1. Carregar os dados\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# Link do arquivo no Google Drive (modificado para download direto)\n",
        "url = \"https://drive.google.com/uc?export=download&id=1lh6LrxlSQ72aoZ1sJavKSZq-xXSw_ZZg\"\n",
        "\n",
        "# Baixar o conteúdo do arquivo\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    # Corrigindo possíveis problemas de delimitador\n",
        "    conteudo_corrigido = response.content.decode('utf-8').replace(\"\\t\", \";\")\n",
        "\n",
        "    # Lendo o conteúdo como DataFrame\n",
        "    data = pd.read_csv(StringIO(conteudo_corrigido), sep=';', decimal=',')\n",
        "\n",
        "    # Exibindo as primeiras linhas\n",
        "    print(\"Primeiras linhas do DataFrame:\")\n",
        "    print(data.head())\n",
        "\n",
        "    # Exibir informações do DataFrame\n",
        "    print(\"\\nInformações do DataFrame:\")\n",
        "    print(data.info())\n",
        "else:\n",
        "    print(f\"Erro ao baixar o arquivo: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preparação dos dados\n",
        "# Criar a variável alvo: Produto mais propenso a ser comprado\n",
        "# Supomos que cada cliente tende a comprar mais frequentemente o produto que comprou anteriormente\n",
        "# Transformamos os dados para obter a última compra como referência para treinamento\n",
        "data['data_venda'] = pd.to_datetime(data['data_venda'])\n",
        "data.sort_values(['codigo_cliente', 'data_venda'], ascending=True, inplace=True)\n",
        "data['target'] = data.groupby('codigo_cliente')['codigo_produto'].shift(-1)\n",
        "data = data.dropna(subset=['target'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5WGxnVhK-Ec",
        "outputId": "06421c33-c077-4426-aa5d-a46fd6acb32a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-75-280c8ba88931>:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data['data_venda'] = pd.to_datetime(data['data_venda'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Seleção de atributos e preparação\n",
        "\n",
        "# Variáveis categóricas a serem codificadas\n",
        "data['sistema_de_vendas'] = LabelEncoder().fit_transform(data['sistema_de_vendas'])\n",
        "data['tipologia'] = LabelEncoder().fit_transform(data['tipologia'])\n",
        "data['nivel_cliente'] = LabelEncoder().fit_transform(data['nivel_cliente'])\n",
        "data['codigo_produto'] = LabelEncoder().fit_transform(data['codigo_produto'])\n",
        "\n",
        "# Atributos e alvo\n",
        "features = ['codigo_produto', 'unidades_vendidas', 'sistema_de_vendas', 'tipologia', 'nivel_cliente']\n",
        "target = 'target'\n",
        "\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Excluir produtos com amostras insuficientes\n",
        "min_samples = 5\n",
        "product_counts = y.value_counts()\n",
        "valid_products = product_counts[product_counts >= min_samples].index\n",
        "\n",
        "# Filtrar o dataset\n",
        "X = X[y.isin(valid_products)]\n",
        "y = y[y.isin(valid_products)]\n",
        "\n",
        "# Dividir dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZpDveVMLtcP",
        "outputId": "46be2002-f003-4686-9f8c-b66e8f9c8854"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-76-8c84a512a555>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['sistema_de_vendas'] = LabelEncoder().fit_transform(data['sistema_de_vendas'])\n",
            "<ipython-input-76-8c84a512a555>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['tipologia'] = LabelEncoder().fit_transform(data['tipologia'])\n",
            "<ipython-input-76-8c84a512a555>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['nivel_cliente'] = LabelEncoder().fit_transform(data['nivel_cliente'])\n",
            "<ipython-input-76-8c84a512a555>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['codigo_produto'] = LabelEncoder().fit_transform(data['codigo_produto'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Pipeline de processamento e modelagem\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), ['unidades_vendidas']),\n",
        "        ('cat', 'passthrough', ['codigo_produto', 'sistema_de_vendas', 'tipologia', 'nivel_cliente'])\n",
        "    ])\n",
        "\n",
        "# Modelos para testar\n",
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(random_state=42),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'DecisionTree': DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Hiperparâmetros para otimização\n",
        "param_grids = {\n",
        "    'RandomForest': {\n",
        "        'model__n_estimators': [50, 100, 400],\n",
        "        'model__max_depth': [5, 10, None]\n",
        "    },\n",
        "    'LogisticRegression': {\n",
        "        'model__C': [0.01, 0.1, 1, 10, 100]\n",
        "    },\n",
        "    'DecisionTree': {\n",
        "        'model__max_depth': [5, 10, 20, None]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Ajustar validação cruzada estratificada\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Pipeline e GridSearch\n",
        "best_models = {}\n",
        "accuracies = {}\n",
        "for model_name, model in models.items():\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
        "    param_grid = param_grids[model_name]\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_models[model_name] = grid_search.best_estimator_\n",
        "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "    accuracies[model_name] = accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B6dKh8BLLxiD",
        "outputId": "4ec72ce1-01f3-419b-e29b-48a998fd3092"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir os melhores modelos e suas acurácias\n",
        "for model_name, best_model in best_models.items():\n",
        "    print(f\"Melhor modelo para {model_name}: {best_model}\")\n",
        "    print(f\"Acurácia para {model_name}: {accuracies[model_name]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3CBABQjq3hs",
        "outputId": "433b5850-d579-47b0-8b4f-c3e719aae3d0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor modelo para RandomForest: Pipeline(steps=[('preprocessor',\n",
            "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
            "                                                  ['unidades_vendidas']),\n",
            "                                                 ('cat', 'passthrough',\n",
            "                                                  ['codigo_produto',\n",
            "                                                   'sistema_de_vendas',\n",
            "                                                   'tipologia',\n",
            "                                                   'nivel_cliente'])])),\n",
            "                ('model',\n",
            "                 RandomForestClassifier(max_depth=10, n_estimators=50,\n",
            "                                        random_state=42))])\n",
            "Acurácia para RandomForest: 0.4130\n",
            "Melhor modelo para LogisticRegression: Pipeline(steps=[('preprocessor',\n",
            "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
            "                                                  ['unidades_vendidas']),\n",
            "                                                 ('cat', 'passthrough',\n",
            "                                                  ['codigo_produto',\n",
            "                                                   'sistema_de_vendas',\n",
            "                                                   'tipologia',\n",
            "                                                   'nivel_cliente'])])),\n",
            "                ('model',\n",
            "                 LogisticRegression(C=0.01, max_iter=1000, random_state=42))])\n",
            "Acurácia para LogisticRegression: 0.2251\n",
            "Melhor modelo para DecisionTree: Pipeline(steps=[('preprocessor',\n",
            "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
            "                                                  ['unidades_vendidas']),\n",
            "                                                 ('cat', 'passthrough',\n",
            "                                                  ['codigo_produto',\n",
            "                                                   'sistema_de_vendas',\n",
            "                                                   'tipologia',\n",
            "                                                   'nivel_cliente'])])),\n",
            "                ('model',\n",
            "                 DecisionTreeClassifier(max_depth=10, random_state=42))])\n",
            "Acurácia para DecisionTree: 0.4041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerar ranking de produtos por cliente\n",
        "X_test['codigo_cliente'] = data.loc[X_test.index, 'codigo_cliente']  # Restaurar códigos de cliente\n",
        "predictions = pd.DataFrame({\n",
        "    'codigo_cliente': X_test['codigo_cliente'],\n",
        "    'codigo_produto_predito': best_models['RandomForest'].predict(X_test.drop(columns=['codigo_cliente']))\n",
        "})\n",
        "\n",
        "# Gerar ranking agrupado por cliente\n",
        "ranking = predictions.groupby('codigo_cliente')['codigo_produto_predito'].apply(list).reset_index()\n",
        "print(ranking.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fe4J8gvtcpo",
        "outputId": "8f4e0e96-8fc9-4b19-fbda-869b0aca4a2f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   codigo_cliente                             codigo_produto_predito\n",
            "0       100164574  [TORTILHA_PRA MIM, SALGADINHO DE MILHO 2_PRA G...\n",
            "1       100186750  [PRODUTO7_PRA GALERA, BATATAS PREMIUM_PRA GENT...\n",
            "2       100250696  [BATATAS_PRA GENTE, TORTILHA_PRA GALERA, TORTI...\n",
            "3       100250697  [TORTILHA_PRA GALERA, SALGADINHO DE MILHO 1_PR...\n",
            "4       100250802  [TORTILHA_PRA MIM, BATATAS_PRA GENTE, SALGADIN...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Análise de Resultados\n",
        "\n",
        "O código realiza a previsão do próximo produto que um cliente comprará com base em dados históricos de vendas. Vamos analisar os passos e os resultados:\n",
        "\n",
        "\n",
        "**1. Carregamento e Preparação dos Dados:**\n",
        "\n",
        "* Os dados são carregados de um arquivo CSV no Google Drive. O código lida com possíveis problemas de delimitadores, substituindo tabulações por ponto e vírgula.\n",
        "* A variável alvo 'target' é criada representando o código do produto comprado pelo cliente na próxima compra. A ordenação por cliente e data é crucial para essa definição.\n",
        "* As colunas categóricas são codificadas usando `LabelEncoder`, transformando strings em números.\n",
        "* Atributos irrelevantes são removidos e o dataset é dividido em treino e teste.\n",
        "\n",
        "**2. Processamento e Modelagem:**\n",
        "\n",
        "* Um `ColumnTransformer` é usado para pré-processar os dados: `StandardScaler` para a coluna numérica 'unidades_vendidas' e 'passthrough' para as categóricas.\n",
        "* Três modelos de classificação são treinados e testados: RandomForestClassifier, LogisticRegression e DecisionTreeClassifier.\n",
        "* Um `GridSearchCV` otimiza os hiperparâmetros de cada modelo utilizando validação cruzada estratificada (`StratifiedKFold`) para encontrar a melhor configuração.\n",
        "* A acurácia de cada modelo no conjunto de teste é calculada.\n",
        "\n",
        "**3. Resultados e Análise:**\n",
        "\n",
        "* O código imprime o melhor modelo e a acurácia para cada algoritmo testado.  A acurácia é uma métrica importante, mas, dependendo do contexto e do desbalanceamento das classes, outras métricas como precisão, recall, F1-score e AUC podem ser mais relevantes.\n",
        "* Um ranking dos produtos mais propensos a serem comprados por cada cliente é gerado usando as previsões do melhor modelo (RandomForest). A saída é um DataFrame com o código do cliente e uma lista dos produtos previstos.\n",
        "\n",
        "\n",
        "**Pontos a serem considerados:**\n",
        "\n",
        "Em resumo, o código fornece uma base sólida para previsão da próxima compra, mas exige ainda um refinamento e análise mais aprofundada para garantir a qualidade das predições.  Será necessário avaliar mais as métricas, realizar testes mais robustos, considerar outras variáveis e validar as hipóteses para melhorar a precisão e a confiabilidade do modelo.\n"
      ],
      "metadata": {
        "id": "9t-_t-3s4TDu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}